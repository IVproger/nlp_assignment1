{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-sensitive Spelling Correction\n",
    "\n",
    "### Student: Ivan Golov\n",
    "### Email: i.golov@innopolis.university\n",
    "### Group: AI-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norvig's solution evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started working on the Assignment by evaluating the Norvig's solution and hightlighting the main drawbacks of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the train language corpus using nltk.corpus import gutenberg, reuters, brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/ivangolov/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/ivangolov/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/ivangolov/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large corpus generated and saved to 'data/train/language_corpus.txt'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('reuters')\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg, reuters, brown\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to generate large corpus text\n",
    "def generate_large_corpus():\n",
    "    large_corpus_text = \"\"\n",
    "\n",
    "    # List of all Gutenberg file IDs\n",
    "    file_ids = gutenberg.fileids()\n",
    "\n",
    "    # Generate the large corpus by combining all texts\n",
    "    large_corpus_text = \"\\n\".join(gutenberg.raw(file_id) for file_id in file_ids)\n",
    "\n",
    "    # Add Reuters and Brown corpora to the large corpus\n",
    "    reuters_text = \" \".join(reuters.words())\n",
    "    brown_text = \" \".join(brown.words())\n",
    "\n",
    "    large_corpus_text += f\"\\n{reuters_text}\\n{brown_text}\"\n",
    "\n",
    "    return large_corpus_text\n",
    "\n",
    "# Save the large corpus to a text file\n",
    "def save_large_corpus(file_path, corpus_text):\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(corpus_text)\n",
    "\n",
    "# Generate and save the large corpus\n",
    "large_corpus_text = generate_large_corpus()\n",
    "save_large_corpus(\"data/train/language_corpus.txt\", large_corpus_text)\n",
    "print(\"Large corpus generated and saved to 'data/train/language_corpus.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the Norvig model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NorvigSpellingCorrector_v1:\n",
    "    def __init__(self, corpus):\n",
    "        self.WORDS = Counter(self.words(corpus))\n",
    "        self.N = sum(self.WORDS.values())\n",
    "\n",
    "    def words(self, text):\n",
    "        return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "    def P(self, word):\n",
    "        \"Probability of `word`.\"\n",
    "        return self.WORDS[word] / self.N\n",
    "\n",
    "    def correction(self, word):\n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(self.candidates(word), key=self.P)\n",
    "\n",
    "    def candidates(self, word):\n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word])\n",
    "\n",
    "    def known(self, words):\n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(w for w in words if w in self.WORDS)\n",
    "\n",
    "    def edits1(self, word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(self, word):\n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NorvigSpellingCorrector_v1(large_corpus_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/ivangolov/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = \"\"\n",
    "with open('data/test/test.txt') as f:\n",
    "    test_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the document into sentences\n",
    "sentences = sent_tokenize(test_data.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Initialize lists to store the data for the DataFrame\n",
    "original_sentences = []\n",
    "misspelled_sentences = []\n",
    "correct_words = []\n",
    "misspelled_words = []\n",
    "\n",
    "# Define a regex pattern to find the <ERR> tags\n",
    "pattern = re.compile(r'<err targ=(.*?)>(.*?)</err>')\n",
    "\n",
    "# Define a preprocessing function\n",
    "def preprocess_sentence(sentence):\n",
    "    # Convert to lowercase\n",
    "    sentence = sentence.lower()\n",
    "    # Remove punctuation\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    # Remove extra whitespaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
    "    return sentence\n",
    "\n",
    "# Process each sentence\n",
    "for sentence in sentences:\n",
    "    matches = pattern.findall(sentence)\n",
    "    if matches:\n",
    "        original_sentence = sentence\n",
    "        misspelled_sentence = sentence\n",
    "        correct_word_list = []\n",
    "        misspelled_word_list = []\n",
    "        \n",
    "        for match in matches:\n",
    "            correct_word = match[0]\n",
    "            misspelled_word = match[1]\n",
    "            misspelled_word_mew = match[1].replace(' ', '')\n",
    "            correct_word_list.append(correct_word)\n",
    "            misspelled_word_list.append(misspelled_word_mew)\n",
    "            misspelled_sentence = misspelled_sentence.replace(f'<err targ={correct_word}>{misspelled_word}</err>', misspelled_word_mew)\n",
    "            original_sentence = original_sentence.replace(f'<err targ={correct_word}>{misspelled_word}</err>', correct_word)\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        original_sentence = preprocess_sentence(original_sentence)\n",
    "        misspelled_sentence = preprocess_sentence(misspelled_sentence)\n",
    "        \n",
    "        original_sentences.append(original_sentence)\n",
    "        misspelled_sentences.append(misspelled_sentence)\n",
    "        correct_words.append(correct_word_list)\n",
    "        misspelled_words.append(misspelled_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Original Sentence  \\\n",
      "0  1 nigel thrush page 48 i have four in my famil...   \n",
      "1                          my sister goes to tonbury   \n",
      "2                          my mum goes out sometimes   \n",
      "3  i go to bridgebrook i go out sometimes on tues...   \n",
      "4  on thursday nights i go bellringing on saturda...   \n",
      "\n",
      "                                 Misspelled Sentence      Correct Words  \\\n",
      "0  1 nigel thrush page 48 i have four in my famil...           [sister]   \n",
      "1                             my siter go to tonbury     [sister, goes]   \n",
      "2                          my mum goes out sometimes        [sometimes]   \n",
      "3  i go to bridgebrook i go out sometimes on tues...  [sometimes, club]   \n",
      "4  on thursday nights i go bellringing on saturda...      [bellringing]   \n",
      "\n",
      "    Misspelled Words  \n",
      "0            [siter]  \n",
      "1        [siter, go]  \n",
      "2        [sometimes]  \n",
      "3  [sometimes, clob]  \n",
      "4      [bellringing]  \n"
     ]
    }
   ],
   "source": [
    "# Construct the pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Original Sentence': original_sentences,\n",
    "    'Misspelled Sentence': misspelled_sentences,\n",
    "    'Correct Words': correct_words,\n",
    "    'Misspelled Words': misspelled_words\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('data/test/test_data_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Sentence</th>\n",
       "      <th>Misspelled Sentence</th>\n",
       "      <th>Correct Words</th>\n",
       "      <th>Misspelled Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 nigel thrush page 48 i have four in my famil...</td>\n",
       "      <td>1 nigel thrush page 48 i have four in my famil...</td>\n",
       "      <td>[sister]</td>\n",
       "      <td>[siter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my sister goes to tonbury</td>\n",
       "      <td>my siter go to tonbury</td>\n",
       "      <td>[sister, goes]</td>\n",
       "      <td>[siter, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my mum goes out sometimes</td>\n",
       "      <td>my mum goes out sometimes</td>\n",
       "      <td>[sometimes]</td>\n",
       "      <td>[sometimes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i go to bridgebrook i go out sometimes on tues...</td>\n",
       "      <td>i go to bridgebrook i go out sometimes on tues...</td>\n",
       "      <td>[sometimes, club]</td>\n",
       "      <td>[sometimes, clob]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on thursday nights i go bellringing on saturda...</td>\n",
       "      <td>on thursday nights i go bellringing on saturda...</td>\n",
       "      <td>[bellringing]</td>\n",
       "      <td>[bellringing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i go to bed at 10 o clock i watch tv at 5 o cl...</td>\n",
       "      <td>i go to bed at 10 o clock i wakh tv at 5 o clo...</td>\n",
       "      <td>[watch]</td>\n",
       "      <td>[wakh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the house is white it has stone up the front i...</td>\n",
       "      <td>the house is white it has stone up the frount ...</td>\n",
       "      <td>[front, second]</td>\n",
       "      <td>[frount, sexeon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>on monday i sometimes go down the farm in the ...</td>\n",
       "      <td>on monday i sometimes go down the farm in the ...</td>\n",
       "      <td>[watch]</td>\n",
       "      <td>[wach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>we have got anglia like to watch cowboys</td>\n",
       "      <td>we have got anglia like to wach cowboys</td>\n",
       "      <td>[watch, cowboys]</td>\n",
       "      <td>[wach, cowboys]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>on tuesday i get off the bus and sometimes in ...</td>\n",
       "      <td>on tuesday i get off the bus and sometimes in ...</td>\n",
       "      <td>[sometimes, club]</td>\n",
       "      <td>[sometimes, colbe]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Original Sentence  \\\n",
       "0  1 nigel thrush page 48 i have four in my famil...   \n",
       "1                          my sister goes to tonbury   \n",
       "2                          my mum goes out sometimes   \n",
       "3  i go to bridgebrook i go out sometimes on tues...   \n",
       "4  on thursday nights i go bellringing on saturda...   \n",
       "5  i go to bed at 10 o clock i watch tv at 5 o cl...   \n",
       "6  the house is white it has stone up the front i...   \n",
       "7  on monday i sometimes go down the farm in the ...   \n",
       "8           we have got anglia like to watch cowboys   \n",
       "9  on tuesday i get off the bus and sometimes in ...   \n",
       "\n",
       "                                 Misspelled Sentence      Correct Words  \\\n",
       "0  1 nigel thrush page 48 i have four in my famil...           [sister]   \n",
       "1                             my siter go to tonbury     [sister, goes]   \n",
       "2                          my mum goes out sometimes        [sometimes]   \n",
       "3  i go to bridgebrook i go out sometimes on tues...  [sometimes, club]   \n",
       "4  on thursday nights i go bellringing on saturda...      [bellringing]   \n",
       "5  i go to bed at 10 o clock i wakh tv at 5 o clo...            [watch]   \n",
       "6  the house is white it has stone up the frount ...    [front, second]   \n",
       "7  on monday i sometimes go down the farm in the ...            [watch]   \n",
       "8            we have got anglia like to wach cowboys   [watch, cowboys]   \n",
       "9  on tuesday i get off the bus and sometimes in ...  [sometimes, club]   \n",
       "\n",
       "     Misspelled Words  \n",
       "0             [siter]  \n",
       "1         [siter, go]  \n",
       "2         [sometimes]  \n",
       "3   [sometimes, clob]  \n",
       "4       [bellringing]  \n",
       "5              [wakh]  \n",
       "6    [frount, sexeon]  \n",
       "7              [wach]  \n",
       "8     [wach, cowboys]  \n",
       "9  [sometimes, colbe]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk.metrics import edit_distance as Levenshtein\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import ast\n",
    "\n",
    "# Define the functions to calculate WER and CER\n",
    "def calculate_wer(reference, corrected):\n",
    "    # Calculate Word Error Rate (WER)\n",
    "    reference_words = reference.split()\n",
    "    corrected_words = corrected.split()\n",
    "\n",
    "    S = Levenshtein(reference_words, corrected_words)\n",
    "    I = max(0, len(corrected_words) - len(reference_words))\n",
    "    D = max(0, len(reference_words) - len(corrected_words))\n",
    "\n",
    "    N = max(len(reference_words), len(corrected_words))\n",
    "\n",
    "    wer = (S + I + D) / N\n",
    "\n",
    "    return wer\n",
    "\n",
    "def calculate_cer(reference, corrected):\n",
    "    # Calculate Character Error Rate (CER)\n",
    "    S = Levenshtein(reference, corrected)\n",
    "    I = max(0, len(corrected) - len(reference))\n",
    "    D = max(0, len(reference) - len(corrected))\n",
    "\n",
    "    N = max(len(reference), len(corrected))\n",
    "\n",
    "    cer = (S + I + D) / N\n",
    "\n",
    "    return cer\n",
    "\n",
    "# Define the function to calculate accuracy\n",
    "def calculate_accuracy(df):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        correct_words = ast.literal_eval(row['Correct Words'])\n",
    "        corrected_words = row['Corrected Words']\n",
    "        for correct_word, corrected_word in zip(correct_words, corrected_words):\n",
    "            if correct_word == corrected_word:\n",
    "                correct_predictions += 1\n",
    "            total_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "def calculate_perplexity_norvig(sentence, model):\n",
    "    words = model.words(sentence)\n",
    "    log_prob = 0\n",
    "\n",
    "    for word in words:\n",
    "        prob = model.P(word)\n",
    "        if prob > 0:\n",
    "            log_prob += np.log2(prob)  \n",
    "        else:\n",
    "            log_prob += np.log2(1 / model.N) \n",
    "\n",
    "    HC = -log_prob / len(words)  # Cross-entropy\n",
    "    perpl = math.pow(2, HC)  # Perplexity\n",
    "\n",
    "    return HC, perpl\n",
    "\n",
    "def correct_sentence(sentence, model):\n",
    "    return ' '.join([model.correction(word) for word in model.words(sentence)])\n",
    "\n",
    "def correct_words(words, model):\n",
    "    return [model.correction(word.strip()) for word in eval(words)]\n",
    "\n",
    "def compute_stats(df, model, tag):\n",
    "    WER = []\n",
    "    CER = []\n",
    "    accuracy = 0\n",
    "    perplexities = []\n",
    "    HCs = []\n",
    "\n",
    "    if tag == \"Norvig\":\n",
    "        \n",
    "        print(\"Compute the corrected sentence and words\")\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            df['Corrected Sentence'] = list(tqdm(executor.map(lambda sentence: correct_sentence(sentence, model), df['Misspelled Sentence']), total=len(df)))\n",
    "            df['Corrected Words'] = list(tqdm(executor.map(lambda words: correct_words(words, model), df['Misspelled Words']), total=len(df)))\n",
    "        \n",
    "        print(\"Compute the WER, CER and Perplexity\")\n",
    "        for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "            reference = row['Original Sentence']\n",
    "            corrected = row['Corrected Sentence']\n",
    "            wer = calculate_wer(reference, corrected)\n",
    "            cer = calculate_cer(reference, corrected)\n",
    "            WER.append(wer)\n",
    "            CER.append(cer)\n",
    "            HC, perplexity = calculate_perplexity_norvig(corrected, model)\n",
    "            perplexities.append(perplexity)\n",
    "            HCs.append(HC)\n",
    "            \n",
    "        \n",
    "        print(\"Compute the accuracy\")\n",
    "        accuracy = calculate_accuracy(df)\n",
    "            \n",
    "    print('Average Word Error Rate (WER):', np.mean(WER))\n",
    "    print('Average Character Error Rate (CER):', np.mean(CER))\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print('Average Perplexity:', np.mean(perplexities))\n",
    "    print('Average Cross-Entropy:', np.mean(HCs))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_csv('data/test/test_data_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute the corrected sentence and words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 666/666 [00:36<00:00, 18.09it/s] \n",
      "100%|██████████| 666/666 [00:23<00:00, 28.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute the WER, CER and Perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 666/666 [00:28<00:00, 22.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute the accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 666/666 [00:00<00:00, 10956.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Error Rate (WER): 0.12568611368448648\n",
      "Average Character Error Rate (CER): 0.06691358406401805\n",
      "Accuracy: 0.2058484032320123\n",
      "Average Perplexity: 5198.027378935151\n",
      "Average Cross-Entropy: 10.281997326281457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "updated = compute_stats(test_df.copy(), model, \"Norvig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Sentence</th>\n",
       "      <th>Misspelled Sentence</th>\n",
       "      <th>Correct Words</th>\n",
       "      <th>Misspelled Words</th>\n",
       "      <th>Corrected Sentence</th>\n",
       "      <th>Corrected Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 nigel thrush page 48 i have four in my famil...</td>\n",
       "      <td>1 nigel thrush page 48 i have four in my famil...</td>\n",
       "      <td>['sister']</td>\n",
       "      <td>['siter']</td>\n",
       "      <td>1 nigel thrush page 48 i have four in my famil...</td>\n",
       "      <td>[sister]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my sister goes to tonbury</td>\n",
       "      <td>my siter go to tonbury</td>\n",
       "      <td>['sister', 'goes']</td>\n",
       "      <td>['siter', 'go']</td>\n",
       "      <td>my sister go to tilbury</td>\n",
       "      <td>[sister, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my mum goes out sometimes</td>\n",
       "      <td>my mum goes out sometimes</td>\n",
       "      <td>['sometimes']</td>\n",
       "      <td>['sometimes']</td>\n",
       "      <td>my mum goes out sometimes</td>\n",
       "      <td>[sometimes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i go to bridgebrook i go out sometimes on tues...</td>\n",
       "      <td>i go to bridgebrook i go out sometimes on tues...</td>\n",
       "      <td>['sometimes', 'club']</td>\n",
       "      <td>['sometimes', 'clob']</td>\n",
       "      <td>i go to bridgebrook i go out sometimes on tues...</td>\n",
       "      <td>[sometimes, club]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on thursday nights i go bellringing on saturda...</td>\n",
       "      <td>on thursday nights i go bellringing on saturda...</td>\n",
       "      <td>['bellringing']</td>\n",
       "      <td>['bellringing']</td>\n",
       "      <td>on thursday nights i go bellringing on saturda...</td>\n",
       "      <td>[bellringing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i go to bed at 10 o clock i watch tv at 5 o cl...</td>\n",
       "      <td>i go to bed at 10 o clock i wakh tv at 5 o clo...</td>\n",
       "      <td>['watch']</td>\n",
       "      <td>['wakh']</td>\n",
       "      <td>i go to bed at 10 o clock i wash tv at 5 o clo...</td>\n",
       "      <td>[wash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the house is white it has stone up the front i...</td>\n",
       "      <td>the house is white it has stone up the frount ...</td>\n",
       "      <td>['front', 'second']</td>\n",
       "      <td>['frount', 'sexeon']</td>\n",
       "      <td>the house is white it has stone up the front i...</td>\n",
       "      <td>[front, sexton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>on monday i sometimes go down the farm in the ...</td>\n",
       "      <td>on monday i sometimes go down the farm in the ...</td>\n",
       "      <td>['watch']</td>\n",
       "      <td>['wach']</td>\n",
       "      <td>on monday i sometimes go down the farm in the ...</td>\n",
       "      <td>[each]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>we have got anglia like to watch cowboys</td>\n",
       "      <td>we have got anglia like to wach cowboys</td>\n",
       "      <td>['watch', 'cowboys']</td>\n",
       "      <td>['wach', 'cowboys']</td>\n",
       "      <td>we have got anglia like to each cowboys</td>\n",
       "      <td>[each, cowboys]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>on tuesday i get off the bus and sometimes in ...</td>\n",
       "      <td>on tuesday i get off the bus and sometimes in ...</td>\n",
       "      <td>['sometimes', 'club']</td>\n",
       "      <td>['sometimes', 'colbe']</td>\n",
       "      <td>on tuesday i get off the bus and sometimes in ...</td>\n",
       "      <td>[sometimes, cole]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Original Sentence  \\\n",
       "0  1 nigel thrush page 48 i have four in my famil...   \n",
       "1                          my sister goes to tonbury   \n",
       "2                          my mum goes out sometimes   \n",
       "3  i go to bridgebrook i go out sometimes on tues...   \n",
       "4  on thursday nights i go bellringing on saturda...   \n",
       "5  i go to bed at 10 o clock i watch tv at 5 o cl...   \n",
       "6  the house is white it has stone up the front i...   \n",
       "7  on monday i sometimes go down the farm in the ...   \n",
       "8           we have got anglia like to watch cowboys   \n",
       "9  on tuesday i get off the bus and sometimes in ...   \n",
       "\n",
       "                                 Misspelled Sentence          Correct Words  \\\n",
       "0  1 nigel thrush page 48 i have four in my famil...             ['sister']   \n",
       "1                             my siter go to tonbury     ['sister', 'goes']   \n",
       "2                          my mum goes out sometimes          ['sometimes']   \n",
       "3  i go to bridgebrook i go out sometimes on tues...  ['sometimes', 'club']   \n",
       "4  on thursday nights i go bellringing on saturda...        ['bellringing']   \n",
       "5  i go to bed at 10 o clock i wakh tv at 5 o clo...              ['watch']   \n",
       "6  the house is white it has stone up the frount ...    ['front', 'second']   \n",
       "7  on monday i sometimes go down the farm in the ...              ['watch']   \n",
       "8            we have got anglia like to wach cowboys   ['watch', 'cowboys']   \n",
       "9  on tuesday i get off the bus and sometimes in ...  ['sometimes', 'club']   \n",
       "\n",
       "         Misspelled Words                                 Corrected Sentence  \\\n",
       "0               ['siter']  1 nigel thrush page 48 i have four in my famil...   \n",
       "1         ['siter', 'go']                            my sister go to tilbury   \n",
       "2           ['sometimes']                          my mum goes out sometimes   \n",
       "3   ['sometimes', 'clob']  i go to bridgebrook i go out sometimes on tues...   \n",
       "4         ['bellringing']  on thursday nights i go bellringing on saturda...   \n",
       "5                ['wakh']  i go to bed at 10 o clock i wash tv at 5 o clo...   \n",
       "6    ['frount', 'sexeon']  the house is white it has stone up the front i...   \n",
       "7                ['wach']  on monday i sometimes go down the farm in the ...   \n",
       "8     ['wach', 'cowboys']            we have got anglia like to each cowboys   \n",
       "9  ['sometimes', 'colbe']  on tuesday i get off the bus and sometimes in ...   \n",
       "\n",
       "     Corrected Words  \n",
       "0           [sister]  \n",
       "1       [sister, go]  \n",
       "2        [sometimes]  \n",
       "3  [sometimes, club]  \n",
       "4      [bellringing]  \n",
       "5             [wash]  \n",
       "6    [front, sexton]  \n",
       "7             [each]  \n",
       "8    [each, cowboys]  \n",
       "9  [sometimes, cole]  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Norvig spelling corrector model v1\n",
    "* Average Word Error Rate (WER): 0.12577995752833032\n",
    "* Average Character Error Rate (CER): 0.06695512816430119\n",
    "* Accuracy: 0.2058484032320123\n",
    "* Average Perplexity: 5198.027378935151\n",
    "* Average Cross-Entropy: 10.281997326281457"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bla bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Improvement №1** (add advanced text predprocessing, exclude rare words and add <UNK> token):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NorvigSpellingCorrector_v2:\n",
    "    def __init__(self, corpus):\n",
    "        self.WORDS = self.preprocess_corpus(corpus)\n",
    "        self.N = sum(self.WORDS.values())\n",
    "        \n",
    "    def preprocess_corpus(self, corpus):\n",
    "        corpus = corpus.lower()\n",
    "\n",
    "        corpus = re.sub(r'[^a-z0-9\\s]', '', corpus)\n",
    "\n",
    "        tokens = self.words(corpus)  \n",
    "\n",
    "        word_counts = Counter(tokens)\n",
    "        \n",
    "        threshold = 10\n",
    "        vocab = {word for word, count in word_counts.items() if count >= threshold}\n",
    "\n",
    "        tokens = [token if token in vocab else \"<UNK>\" for token in tokens]\n",
    "\n",
    "        word_counts = Counter(tokens)\n",
    "    \n",
    "        return word_counts \n",
    "\n",
    "    def words(self, text):\n",
    "        return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "    def P(self, word):\n",
    "        \"Probability of `word`.\"\n",
    "        return self.WORDS[word] / self.N\n",
    "\n",
    "    def correction(self, word):\n",
    "        \"Most probable spelling correction for word.\"\n",
    "        return max(self.candidates(word), key=self.P)\n",
    "\n",
    "    def candidates(self, word):\n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word])\n",
    "\n",
    "    def known(self, words):\n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(w for w in words if w in self.WORDS)\n",
    "\n",
    "    def edits1(self, word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(self, word):\n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus_text = \"\"\n",
    "with open('data/train/language_corpus.txt') as f:\n",
    "    large_corpus_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NorvigSpellingCorrector_v2(large_corpus_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute the corrected sentence and words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 666/666 [00:52<00:00, 12.70it/s]\n",
      "100%|██████████| 666/666 [00:31<00:00, 21.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute the WER, CER and Perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 666/666 [00:29<00:00, 22.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute the accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 666/666 [00:00<00:00, 9620.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Word Error Rate (WER): 0.12965260361783013\n",
      "Average Character Error Rate (CER): 0.06938579384714089\n",
      "Accuracy: 0.22008464794151597\n",
      "Average Perplexity: 4751.986770267538\n",
      "Average Cross-Entropy: 10.065830773255565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "updated = compute_stats(test_df.copy(), model, \"Norvig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Sentence</th>\n",
       "      <th>Misspelled Sentence</th>\n",
       "      <th>Correct Words</th>\n",
       "      <th>Misspelled Words</th>\n",
       "      <th>Corrected Sentence</th>\n",
       "      <th>Corrected Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 nigel thrush page 48 i have four in my famil...</td>\n",
       "      <td>1 nigel thrush page 48 i have four in my famil...</td>\n",
       "      <td>['sister']</td>\n",
       "      <td>['siter']</td>\n",
       "      <td>1 nigel thrust page 48 i have four in my famil...</td>\n",
       "      <td>[sister]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my sister goes to tonbury</td>\n",
       "      <td>my siter go to tonbury</td>\n",
       "      <td>['sister', 'goes']</td>\n",
       "      <td>['siter', 'go']</td>\n",
       "      <td>my sister go to tonbury</td>\n",
       "      <td>[sister, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my mum goes out sometimes</td>\n",
       "      <td>my mum goes out sometimes</td>\n",
       "      <td>['sometimes']</td>\n",
       "      <td>['sometimes']</td>\n",
       "      <td>my sum goes out sometimes</td>\n",
       "      <td>[sometimes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i go to bridgebrook i go out sometimes on tues...</td>\n",
       "      <td>i go to bridgebrook i go out sometimes on tues...</td>\n",
       "      <td>['sometimes', 'club']</td>\n",
       "      <td>['sometimes', 'clob']</td>\n",
       "      <td>i go to bridgebrook i go out sometimes on tues...</td>\n",
       "      <td>[sometimes, club]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on thursday nights i go bellringing on saturda...</td>\n",
       "      <td>on thursday nights i go bellringing on saturda...</td>\n",
       "      <td>['bellringing']</td>\n",
       "      <td>['bellringing']</td>\n",
       "      <td>on thursday nights i go bellringing on saturda...</td>\n",
       "      <td>[bellringing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i go to bed at 10 o clock i watch tv at 5 o cl...</td>\n",
       "      <td>i go to bed at 10 o clock i wakh tv at 5 o clo...</td>\n",
       "      <td>['watch']</td>\n",
       "      <td>['wakh']</td>\n",
       "      <td>i go to bed at 10 o clock i wash tv at 5 o clo...</td>\n",
       "      <td>[wash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the house is white it has stone up the front i...</td>\n",
       "      <td>the house is white it has stone up the frount ...</td>\n",
       "      <td>['front', 'second']</td>\n",
       "      <td>['frount', 'sexeon']</td>\n",
       "      <td>the house is white it has stone up the front i...</td>\n",
       "      <td>[front, seen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>on monday i sometimes go down the farm in the ...</td>\n",
       "      <td>on monday i sometimes go down the farm in the ...</td>\n",
       "      <td>['watch']</td>\n",
       "      <td>['wach']</td>\n",
       "      <td>on monday i sometimes go down the farm in the ...</td>\n",
       "      <td>[each]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>we have got anglia like to watch cowboys</td>\n",
       "      <td>we have got anglia like to wach cowboys</td>\n",
       "      <td>['watch', 'cowboys']</td>\n",
       "      <td>['wach', 'cowboys']</td>\n",
       "      <td>we have got angle like to each cowboy</td>\n",
       "      <td>[each, cowboy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>on tuesday i get off the bus and sometimes in ...</td>\n",
       "      <td>on tuesday i get off the bus and sometimes in ...</td>\n",
       "      <td>['sometimes', 'club']</td>\n",
       "      <td>['sometimes', 'colbe']</td>\n",
       "      <td>on tuesday i get off the bus and sometimes in ...</td>\n",
       "      <td>[sometimes, cole]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Original Sentence  \\\n",
       "0  1 nigel thrush page 48 i have four in my famil...   \n",
       "1                          my sister goes to tonbury   \n",
       "2                          my mum goes out sometimes   \n",
       "3  i go to bridgebrook i go out sometimes on tues...   \n",
       "4  on thursday nights i go bellringing on saturda...   \n",
       "5  i go to bed at 10 o clock i watch tv at 5 o cl...   \n",
       "6  the house is white it has stone up the front i...   \n",
       "7  on monday i sometimes go down the farm in the ...   \n",
       "8           we have got anglia like to watch cowboys   \n",
       "9  on tuesday i get off the bus and sometimes in ...   \n",
       "\n",
       "                                 Misspelled Sentence          Correct Words  \\\n",
       "0  1 nigel thrush page 48 i have four in my famil...             ['sister']   \n",
       "1                             my siter go to tonbury     ['sister', 'goes']   \n",
       "2                          my mum goes out sometimes          ['sometimes']   \n",
       "3  i go to bridgebrook i go out sometimes on tues...  ['sometimes', 'club']   \n",
       "4  on thursday nights i go bellringing on saturda...        ['bellringing']   \n",
       "5  i go to bed at 10 o clock i wakh tv at 5 o clo...              ['watch']   \n",
       "6  the house is white it has stone up the frount ...    ['front', 'second']   \n",
       "7  on monday i sometimes go down the farm in the ...              ['watch']   \n",
       "8            we have got anglia like to wach cowboys   ['watch', 'cowboys']   \n",
       "9  on tuesday i get off the bus and sometimes in ...  ['sometimes', 'club']   \n",
       "\n",
       "         Misspelled Words                                 Corrected Sentence  \\\n",
       "0               ['siter']  1 nigel thrust page 48 i have four in my famil...   \n",
       "1         ['siter', 'go']                            my sister go to tonbury   \n",
       "2           ['sometimes']                          my sum goes out sometimes   \n",
       "3   ['sometimes', 'clob']  i go to bridgebrook i go out sometimes on tues...   \n",
       "4         ['bellringing']  on thursday nights i go bellringing on saturda...   \n",
       "5                ['wakh']  i go to bed at 10 o clock i wash tv at 5 o clo...   \n",
       "6    ['frount', 'sexeon']  the house is white it has stone up the front i...   \n",
       "7                ['wach']  on monday i sometimes go down the farm in the ...   \n",
       "8     ['wach', 'cowboys']              we have got angle like to each cowboy   \n",
       "9  ['sometimes', 'colbe']  on tuesday i get off the bus and sometimes in ...   \n",
       "\n",
       "     Corrected Words  \n",
       "0           [sister]  \n",
       "1       [sister, go]  \n",
       "2        [sometimes]  \n",
       "3  [sometimes, club]  \n",
       "4      [bellringing]  \n",
       "5             [wash]  \n",
       "6      [front, seen]  \n",
       "7             [each]  \n",
       "8     [each, cowboy]  \n",
       "9  [sometimes, cole]  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Norvig spelling corrector model v2\n",
    "* Average Word Error Rate (WER): 0.12965260361783013\n",
    "* Average Character Error Rate (CER): 0.06938579384714089\n",
    "* Accuracy: 0.22008464794151597\n",
    "* Average Perplexity: 4751.986770267538\n",
    "* Average Cross-Entropy: 10.065830773255565"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bla bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Improvement №2** (Add the notion of context using N-gram models):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and predprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_corpus_text = \"\"\n",
    "with open('data/train/language_corpus.txt') as f:\n",
    "    large_corpus_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus):\n",
    "        corpus = corpus.lower()\n",
    "\n",
    "        corpus = re.sub(r'[^a-z0-9\\s]', '', corpus)\n",
    "\n",
    "        tokens = re.findall(r'\\w+', corpus) \n",
    "        \n",
    "        # exclude single character words\n",
    "        tokens = [token for token in tokens if len(token) > 1]\n",
    "\n",
    "        word_counts = Counter(tokens)\n",
    "        \n",
    "        threshold = 10\n",
    "        vocab = {word for word, count in word_counts.items() if count >= threshold}\n",
    "\n",
    "\n",
    "        return tokens, vocab\n",
    "\n",
    "corpus_words, vocab = preprocess_corpus(large_corpus_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentences(sentences, vocab):\n",
    "    preprocessed_sentences = []\n",
    "    for sentence in tqdm(sentences, total=len(sentences)):\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
    "        tokens = re.findall(r'\\w+', sentence)\n",
    "        preprocessed_sentences.append(tokens)\n",
    "    return preprocessed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_sentences = nltk.sent_tokenize(large_corpus_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248174/248174 [00:03<00:00, 78947.85it/s] \n"
     ]
    }
   ],
   "source": [
    "corpus_sentences_predprocessed = preprocess_sentences(corpus_sentences, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the N-gram stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building n-gram counts: 100%|██████████| 4427046/4427046 [00:14<00:00, 314978.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_ngram_counts(words, max_order):\n",
    "    \"\"\"\n",
    "    Build n-gram counts for orders 1 through max_order.\n",
    "    For unigrams, keys are one-element tuples.\n",
    "    \"\"\"\n",
    "    ngram_counts = {i: defaultdict(int) for i in range(1, max_order + 1)}\n",
    "\n",
    "    for i in tqdm(range(len(words)), desc=\"Building n-gram counts\"):\n",
    "        for order in range(1, max_order + 1):\n",
    "            if i + order <= len(words):\n",
    "                gram = tuple(words[i:i + order])\n",
    "                ngram_counts[order][gram] += 1\n",
    "    \n",
    "    return ngram_counts\n",
    "\n",
    "ngram_counts = build_ngram_counts(corpus_words, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unigram_probability(candidate, ngram_counts, alpha, total_words, V):\n",
    "    \"\"\"\n",
    "    Computes smoothed unigram probability:\n",
    "      P(candidate) = (C(candidate) + alpha) / (total_words + alpha * |V|)\n",
    "    \"\"\"\n",
    "    unigram_count = ngram_counts[1].get((candidate,), 0)\n",
    "    V_size = len(V)\n",
    "    \n",
    "    unigram_probability = (unigram_count + alpha) / (total_words + alpha * V_size)\n",
    "    \n",
    "    return unigram_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the bigram probabilities\n",
    "def compute_bigram_probabilities(w1, w2, ngram_counts, alpha):\n",
    "    \"\"\"\n",
    "    Computes smoothed bigram probability:\n",
    "      P(w2|w1) = (C(w1, w2) + alpha) / (C(w1) + alpha * |V|)\n",
    "    \"\"\"\n",
    "    bigram_count = ngram_counts[2][(w1, w2)]\n",
    "    unigram_count = ngram_counts[1][(w1,)]\n",
    "    \n",
    "    V = len(ngram_counts[1])\n",
    "    \n",
    "    bigram_probability = (bigram_count + alpha) / (unigram_count + alpha * V)\n",
    "    \n",
    "    return bigram_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity_bigram(sentences, ngram_counts, alpha):\n",
    "    \"\"\"\n",
    "    Compute the perplexity of the validation set using the bigram model.\n",
    "    \"\"\"\n",
    "    total_log_prob = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for sentence in tqdm(sentences, desc=\"Computing Perplexity\"):\n",
    "        for i in range(1, len(sentence)):\n",
    "            w1 = sentence[i - 1]\n",
    "            w2 = sentence[i]\n",
    "            bigram_prob = compute_bigram_probabilities(w1, w2, ngram_counts, alpha)\n",
    "            log_prob = np.log2(bigram_prob)\n",
    "            total_log_prob += log_prob\n",
    "            total_words += 1\n",
    "\n",
    "    HC = -total_log_prob / total_words\n",
    "    perplexity = math.pow(2, HC)\n",
    "\n",
    "    return HC, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity_bigram_avg(sentences, ngram_counts, alpha):\n",
    "    \"\"\"\n",
    "    Compute the average perplexity of the validation set using the bigram model.\n",
    "    \"\"\"\n",
    "    total_perplexity = 0\n",
    "    num_sentences = len(sentences)\n",
    "\n",
    "    for sentence in tqdm(sentences, desc=\"Computing Perplexity\"):\n",
    "        total_log_prob = 0\n",
    "        total_words = 0\n",
    "        for i in range(1, len(sentence)):\n",
    "            w1 = sentence[i - 1]\n",
    "            w2 = sentence[i]\n",
    "            bigram_prob = compute_bigram_probabilities(w1, w2, ngram_counts, alpha)\n",
    "            log_prob = np.log2(bigram_prob)\n",
    "            total_log_prob += log_prob\n",
    "            total_words += 1\n",
    "\n",
    "        HC = -total_log_prob / total_words\n",
    "        sentence_perplexity = math.pow(2, HC)\n",
    "        total_perplexity += sentence_perplexity\n",
    "\n",
    "    average_perplexity = total_perplexity / num_sentences\n",
    "\n",
    "    return HC, average_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the trigram probabilities\n",
    "def compute_trigram_probabilities(w1, w2, w3, ngram_counts, alpha):\n",
    "    \"\"\"\n",
    "    Computes smoothed trigram probability:\n",
    "      P(w3|w1, w2) = (C(w1, w2, w3) + alpha) / (C(w1, w2) + alpha * |V|)\n",
    "    \"\"\"\n",
    "    trigram_count = ngram_counts[3][(w1, w2, w3)]\n",
    "    bigram_count = ngram_counts[2][(w1, w2)]\n",
    "    \n",
    "    V = len(ngram_counts[1])\n",
    "    \n",
    "    trigram_probability = (trigram_count + alpha) / (bigram_count + alpha * V)\n",
    "    \n",
    "    return trigram_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity_trigram(sentences, ngram_counts, alpha):\n",
    "    \"\"\"\n",
    "    Compute the perplexity of the validation set using the trigram model.\n",
    "    \"\"\"\n",
    "    total_log_prob = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for sentence in tqdm(sentences, desc=\"Computing Perplexity\"):\n",
    "        for i in range(2, len(sentence)):\n",
    "            w1 = sentence[i - 2]\n",
    "            w2 = sentence[i - 1]\n",
    "            w3 = sentence[i]\n",
    "            trigram_prob = compute_trigram_probabilities(w1, w2, w3, ngram_counts, alpha)\n",
    "            log_prob = np.log2(trigram_prob)\n",
    "            total_log_prob += log_prob\n",
    "            total_words += 1\n",
    "\n",
    "    HC = -total_log_prob / total_words\n",
    "    perplexity = math.pow(2, HC)\n",
    "\n",
    "    return HC, perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolated bi-gram and tri-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_interpolated_prob(w1, w2, w3, ngram_counts, alpha, lamda):\n",
    "    \"\"\"\n",
    "    Computes the interpolated probability:\n",
    "      P(w3|w1,w2) = lam * P_trigram(w3|w1,w2) + (1 - lam) * P_bigram(w3|w2)\n",
    "    where the bigram probability is computed as:\n",
    "      P(w3|w2) = (C(w2, w3) + alpha) / (C(w2) + alpha * |V|)\n",
    "    \"\"\"\n",
    "    # Trigram probability\n",
    "    p_trigram = compute_trigram_probabilities(w1, w2, w3, ngram_counts, alpha)\n",
    "    \n",
    "    # Bigram probability\n",
    "    p_bigram = compute_bigram_probabilities(w2, w3, ngram_counts, alpha)\n",
    "    \n",
    "    # Interpolated probability\n",
    "    interpolated_prob = lamda * p_trigram + (1 - lamda) * p_bigram\n",
    "    \n",
    "    return interpolated_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity_interpolated(sentences, ngram_counts, alpha, lamda):\n",
    "    \"\"\"\n",
    "    Compute the perplexity of the validation set using the interpolated model.\n",
    "    \"\"\"\n",
    "    total_log_prob = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for sentence in tqdm(sentences, desc=\"Computing Perplexity\"):\n",
    "        for i in range(2, len(sentence)):\n",
    "            w1 = sentence[i - 2]\n",
    "            w2 = sentence[i - 1]\n",
    "            w3 = sentence[i]\n",
    "            interpolated_prob = compute_interpolated_prob(w1, w2, w3, ngram_counts, alpha, lamda)\n",
    "            log_prob = np.log2(interpolated_prob)\n",
    "            total_log_prob += log_prob\n",
    "            total_words += 1\n",
    "\n",
    "    HC = -total_log_prob / total_words\n",
    "    perplexity = math.pow(2, HC)\n",
    "\n",
    "    return HC, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity_interpolated_avg(sentences, ngram_counts, alpha, lamda):\n",
    "    \"\"\"\n",
    "    Compute the average perplexity of the validation set using the interpolated model.\n",
    "    \"\"\"\n",
    "    total_perplexity = 0\n",
    "    num_sentences = len(sentences)\n",
    "\n",
    "    for sentence in tqdm(sentences, desc=\"Computing Perplexity\"):\n",
    "        total_log_prob = 0\n",
    "        total_words = 0\n",
    "        for i in range(2, len(sentence)):\n",
    "            w1 = sentence[i - 2]\n",
    "            w2 = sentence[i - 1]\n",
    "            w3 = sentence[i]\n",
    "            interpolated_prob = compute_interpolated_prob(w1, w2, w3, ngram_counts, alpha, lamda)\n",
    "            log_prob = np.log2(interpolated_prob)\n",
    "            total_log_prob += log_prob\n",
    "            total_words += 1\n",
    "\n",
    "        HC = -total_log_prob / total_words\n",
    "        sentence_perplexity = math.pow(2, HC)\n",
    "        total_perplexity += sentence_perplexity\n",
    "\n",
    "    average_perplexity = total_perplexity / num_sentences\n",
    "\n",
    "    return HC, average_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ngram_probability(context, candidate, ngram_counts, alpha, V):\n",
    "    \"\"\"\n",
    "    Computes smoothed n-gram probability:\n",
    "      P(candidate|context) = (C(context, candidate) + alpha) / (C(context) + alpha * |V|)\n",
    "    \"\"\"\n",
    "    context_length = len(context)\n",
    "    ngram_count = ngram_counts.get(context_length + 1, {}).get(context + (candidate,), 0)\n",
    "    context_count = ngram_counts.get(context_length, {}).get(context, 0)\n",
    "    V_size = len(V)\n",
    "    \n",
    "    ngram_probability = (ngram_count + alpha) / (context_count + alpha * V_size)\n",
    "    \n",
    "    return ngram_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for the bigram LM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:01<00:00, 5044.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0001, Cross-Entropy: 15.571766524590013, Perplexity: 48704.46861441161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:01<00:00, 5151.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001, Cross-Entropy: 14.330228241264058, Perplexity: 20598.16559884154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:01<00:00, 5164.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Cross-Entropy: 13.369777434082627, Perplexity: 10585.321255172768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:01<00:00, 5141.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Cross-Entropy: 13.225124444839032, Perplexity: 9575.449149327107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:02<00:00, 4936.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.2, Cross-Entropy: 13.332784876705192, Perplexity: 10317.350239208281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:01<00:00, 5026.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.3, Cross-Entropy: 13.413407114210472, Perplexity: 10910.32996801804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:01<00:00, 5213.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.5, Cross-Entropy: 13.525765811997951, Perplexity: 11794.002723707026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:01<00:00, 5114.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1.0, Cross-Entropy: 13.684862012267859, Perplexity: 13169.03500911066\n",
      "Tuning hyperparameters for the trigram LM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:02<00:00, 4065.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0001, Cross-Entropy: 14.620505569248602, Perplexity: 25188.98849920805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:02<00:00, 4396.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001, Cross-Entropy: 14.206140808074235, Perplexity: 18900.55277083627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:02<00:00, 4244.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Cross-Entropy: 14.159908223480418, Perplexity: 18304.46800107179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:02<00:00, 4483.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Cross-Entropy: 14.215964158776348, Perplexity: 19029.686298875287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:02<00:00, 4257.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.2, Cross-Entropy: 14.236179841975247, Perplexity: 19298.215691654135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:02<00:00, 4436.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.3, Cross-Entropy: 14.247777104562108, Perplexity: 19453.971710877144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:02<00:00, 4391.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.5, Cross-Entropy: 14.261719897904568, Perplexity: 19642.89427053955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:02<00:00, 4448.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1.0, Cross-Entropy: 14.278660100343172, Perplexity: 19874.90164292532\n",
      "Tuning hyperparameters for the interpolated LM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3003.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0001, Lambda: 0.1, Cross-Entropy: 13.74841975635381, Perplexity: 13762.16434002628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3085.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0001, Lambda: 0.2, Cross-Entropy: 13.421845623129277, Perplexity: 10974.332889969628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3076.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0001, Lambda: 0.3, Cross-Entropy: 13.251782886276027, Perplexity: 9754.031298146649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3071.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0001, Lambda: 0.5, Cross-Entropy: 13.104681697956275, Perplexity: 8808.506410006923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3106.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0001, Lambda: 0.7, Cross-Entropy: 13.126402758739374, Perplexity: 8942.129716459292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3051.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0001, Lambda: 0.9, Cross-Entropy: 13.420482816570608, Perplexity: 10963.971149767824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2952.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001, Lambda: 0.1, Cross-Entropy: 13.388771662904029, Perplexity: 10725.606896728907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3092.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001, Lambda: 0.2, Cross-Entropy: 13.133015829305382, Perplexity: 8983.213017329448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3108.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001, Lambda: 0.3, Cross-Entropy: 12.990919827534746, Perplexity: 8140.602319926089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3092.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001, Lambda: 0.5, Cross-Entropy: 12.865048054124225, Perplexity: 7460.455769840212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3108.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001, Lambda: 0.7, Cross-Entropy: 12.889988452461294, Perplexity: 7590.5486469191455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2993.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001, Lambda: 0.9, Cross-Entropy: 13.170092411617906, Perplexity: 9217.069485687693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3098.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Lambda: 0.1, Cross-Entropy: 13.054219315058122, Perplexity: 8505.72982676796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2903.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Lambda: 0.2, Cross-Entropy: 12.95266768545199, Perplexity: 7927.595768650709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2895.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Lambda: 0.3, Cross-Entropy: 12.898792610216251, Perplexity: 7637.012184923165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3069.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Lambda: 0.5, Cross-Entropy: 12.874492605207696, Perplexity: 7509.455587400954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2707.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Lambda: 0.7, Cross-Entropy: 12.956232928853806, Perplexity: 7947.210974771716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3135.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.01, Lambda: 0.9, Cross-Entropy: 13.264261707383362, Perplexity: 9838.766285362026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3074.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Lambda: 0.1, Cross-Entropy: 13.171630429860954, Perplexity: 9226.900794201996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3035.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Lambda: 0.2, Cross-Entropy: 13.165096248539044, Perplexity: 9185.205276259956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3094.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Lambda: 0.3, Cross-Entropy: 13.176780061465879, Perplexity: 9259.894629423752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3134.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Lambda: 0.5, Cross-Entropy: 13.243434492534057, Perplexity: 9697.750975674371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2921.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Lambda: 0.7, Cross-Entropy: 13.381695482825537, Perplexity: 10673.128376878805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2810.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Lambda: 0.9, Cross-Entropy: 13.688399665414488, Perplexity: 13201.366612424476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3093.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.2, Lambda: 0.1, Cross-Entropy: 13.313993041498236, Perplexity: 10183.832968208546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3032.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.2, Lambda: 0.2, Cross-Entropy: 13.322878081900287, Perplexity: 10246.745064096416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2722.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.2, Lambda: 0.3, Cross-Entropy: 13.344439653685741, Perplexity: 10401.036276166316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3096.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.2, Lambda: 0.5, Cross-Entropy: 13.422026880278523, Perplexity: 10975.711768527679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2755.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.2, Lambda: 0.7, Cross-Entropy: 13.560104693680929, Perplexity: 12078.089880640742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3124.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.2, Lambda: 0.9, Cross-Entropy: 13.836544304785765, Perplexity: 14629.007820328075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3059.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.3, Lambda: 0.1, Cross-Entropy: 13.408380719477208, Perplexity: 10872.38417705044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3082.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.3, Lambda: 0.2, Cross-Entropy: 13.423816716442913, Perplexity: 10989.336904925754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3075.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.3, Lambda: 0.3, Cross-Entropy: 13.449282648171627, Perplexity: 11185.03885910331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2978.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.3, Lambda: 0.5, Cross-Entropy: 13.529699897031351, Perplexity: 11826.207679021836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3116.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.3, Lambda: 0.7, Cross-Entropy: 13.66336565997831, Perplexity: 12974.269218489815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3077.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.3, Lambda: 0.9, Cross-Entropy: 13.915883410354882, Perplexity: 15456.04319086476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3131.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.5, Lambda: 0.1, Cross-Entropy: 13.532514455118235, Perplexity: 11849.301983139223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3095.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.5, Lambda: 0.2, Cross-Entropy: 13.553571800189744, Perplexity: 12023.520833735003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3046.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.5, Lambda: 0.3, Cross-Entropy: 13.581963683365942, Perplexity: 12262.48442318979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3097.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.5, Lambda: 0.5, Cross-Entropy: 13.662285258617828, Perplexity: 12964.55672183208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3107.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.5, Lambda: 0.7, Cross-Entropy: 13.786314718599488, Perplexity: 14128.44157281574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3093.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.5, Lambda: 0.9, Cross-Entropy: 14.004445186616572, Perplexity: 16434.559717363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:04<00:00, 2428.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1.0, Lambda: 0.1, Cross-Entropy: 13.699871746504796, Perplexity: 13306.760257644217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2692.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1.0, Lambda: 0.2, Cross-Entropy: 13.724104298991048, Perplexity: 13532.15792823409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 3016.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1.0, Lambda: 0.3, Cross-Entropy: 13.753030375680103, Perplexity: 13806.216338878241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2884.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1.0, Lambda: 0.5, Cross-Entropy: 13.82730146463481, Perplexity: 14535.584492750848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2976.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1.0, Lambda: 0.7, Cross-Entropy: 13.932713511762609, Perplexity: 15637.40513465185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Perplexity: 100%|██████████| 10000/10000 [00:03<00:00, 2822.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1.0, Lambda: 0.9, Cross-Entropy: 14.101701637133313, Perplexity: 17580.66031082511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tune the hyperparameters for the bigram LM\n",
    "validation_set = corpus_sentences[:10000]\n",
    "alpha_values = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.5, 1.0]\n",
    "lambda_values = [0.1, 0.2, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "best_bigram_params=None\n",
    "best_bigram_ce = float('inf')\n",
    "print(\"Tuning hyperparameters for the bigram LM:\")\n",
    "for alpha in (alpha_values):\n",
    "    HC, perpl = compute_perplexity_bigram(validation_set, ngram_counts, alpha)\n",
    "    print(f\"Alpha: {alpha}, Cross-Entropy: {HC}, Perplexity: {perpl}\")\n",
    "    if HC < best_bigram_ce:\n",
    "        best_bigram_ce = HC\n",
    "        best_bigram_params = (alpha, HC, perpl)\n",
    "        \n",
    "# Tune the hyperparameters for the trigram LM\n",
    "best_trigram_params=None\n",
    "best_trigram_ce = float('inf')\n",
    "print(\"Tuning hyperparameters for the trigram LM:\")\n",
    "for alpha in (alpha_values):\n",
    "    HC, perpl = compute_perplexity_trigram(validation_set, ngram_counts, alpha)\n",
    "    print(f\"Alpha: {alpha}, Cross-Entropy: {HC}, Perplexity: {perpl}\")\n",
    "    if HC < best_trigram_ce:\n",
    "        best_trigram_ce = HC\n",
    "        best_trigram_params = (alpha, HC, perpl)\n",
    "        \n",
    "# Tune the hyperparameters for the interpolated LM\n",
    "best_interpolated_params=None\n",
    "best_interpolated_ce = float('inf')\n",
    "print(\"Tuning hyperparameters for the interpolated LM:\")\n",
    "for alpha in (alpha_values):\n",
    "    for lamda in lambda_values:\n",
    "        HC, perpl = compute_perplexity_interpolated(validation_set, ngram_counts, alpha, lamda)\n",
    "        print(f\"Alpha: {alpha}, Lambda: {lamda}, Cross-Entropy: {HC}, Perplexity: {perpl}\")\n",
    "        if HC < best_interpolated_ce:\n",
    "            best_interpolated_ce = HC\n",
    "            best_interpolated_params = (alpha, lamda, HC, perpl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for the bigram LM:\n",
      "Alpha: 0.1, Cross-Entropy: 13.225124444839032, Perplexity: 9575.449149327107\n",
      "Best hyperparameters for the trigram LM:\n",
      "Alpha: 0.01, Cross-Entropy: 14.159908223480418, Perplexity: 18304.46800107179\n",
      "Best hyperparameters for the interpolated LM:\n",
      "Alpha: 0.001, Lambda: 0.5, Cross-Entropy: 12.865048054124225, Perplexity: 7460.455769840212\n"
     ]
    }
   ],
   "source": [
    "# Print best paraneters\n",
    "print(\"Best hyperparameters for the bigram LM:\")\n",
    "print(f\"Alpha: {best_bigram_params[0]}, Cross-Entropy: {best_bigram_params[1]}, Perplexity: {best_bigram_params[2]}\")\n",
    "print(\"Best hyperparameters for the trigram LM:\")\n",
    "print(f\"Alpha: {best_trigram_params[0]}, Cross-Entropy: {best_trigram_params[1]}, Perplexity: {best_trigram_params[2]}\")\n",
    "print(\"Best hyperparameters for the interpolated LM:\")\n",
    "print(f\"Alpha: {best_interpolated_params[0]}, Lambda: {best_interpolated_params[1]}, Cross-Entropy: {best_interpolated_params[2]}, Perplexity: {best_interpolated_params[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best hyperparameters\n",
    "best_hyperparameters = {\n",
    "    \"bigram\": best_bigram_params,\n",
    "    \"trigram\": best_trigram_params,\n",
    "    \"interpolated\": best_interpolated_params\n",
    "}\n",
    "\n",
    "\n",
    "with open('data/train/best_hyperparameters.json', 'w') as f:\n",
    "    json.dump(best_hyperparameters, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context-Sensitive Correction based on N-gram model and beam seacrh approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = None\n",
    "with open('data/train/best_hyperparameters.json', 'r') as f:\n",
    "    best_hyperparameters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bigram_alpha = best_hyperparameters['bigram'][0]\n",
    "best_trigram_alpha = best_hyperparameters['trigram'][0]\n",
    "best_interpolated_alpha = best_hyperparameters['interpolated'][0]\n",
    "best_interpolated_lambda = best_hyperparameters['interpolated'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "@lru_cache(maxsize=None)\n",
    "def get_candidates(word, V):\n",
    "    def known(words, V):\n",
    "        return set(w for w in words if w in V)\n",
    "    \n",
    "    def edits1(word):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes = [L + R[1:] for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "        inserts = [L + c + R for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "    \n",
    "    def edits2(word):\n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "    \n",
    "    def edits3(word):\n",
    "        \"All edits that are three edits away from `word`.\"\n",
    "        return (e3 for e2 in edits1(word) for e3 in edits1(e2))\n",
    "    \n",
    "    return known([word], V) or known(edits1(word), V) or known(edits2(word), V) or known(edits3(word), V) or {word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq\n",
    "\n",
    "def corrector_with_beam_search(sentence, V, ngram_counts, beam_width=2, n=3, alpha=0.01, lamda=0.5):\n",
    "    sentence_tokens = preprocess_sentences([sentence], V)[0]\n",
    "    candidates_sequences = [(0.0, [])]\n",
    "    total_words = len(V)\n",
    "    \n",
    "    for word in sentence_tokens:\n",
    "        new_candidates_sequences = []\n",
    "        candidate_list = get_candidates(word, V)\n",
    "        \n",
    "        for candidate in candidate_list:\n",
    "            for score, sequence in candidates_sequences:\n",
    "                context_length = min(n - 1, len(sequence))\n",
    "                if context_length == 0:\n",
    "                    prob = compute_unigram_probability(candidate, ngram_counts, alpha, total_words, V)\n",
    "                elif context_length == 1:\n",
    "                    context = tuple(sequence[-1:])\n",
    "                    prob = compute_bigram_probabilities(context[0], candidate, ngram_counts, best_bigram_alpha)\n",
    "                elif context_length == 2:\n",
    "                    w1, w2 = sequence[-2], sequence[-1]\n",
    "                    prob = compute_interpolated_prob(w1, w2, candidate, ngram_counts, best_interpolated_alpha, best_interpolated_lambda)\n",
    "                else:\n",
    "                    context = tuple(sequence[-context_length:])\n",
    "                    prob = compute_ngram_probability(context, candidate, ngram_counts, alpha, V)\n",
    "                \n",
    "                new_score = score + math.log(prob)\n",
    "                new_seq = sequence + [candidate]\n",
    "                heapq.heappush(new_candidates_sequences, (new_score, new_seq))\n",
    "                if len(new_candidates_sequences) > beam_width:\n",
    "                    heapq.heappop(new_candidates_sequences)\n",
    "        \n",
    "        candidates_sequences = new_candidates_sequences\n",
    "    \n",
    "    best_score, best_seq = max(candidates_sequences, key=lambda x: x[0])\n",
    "    return ' '.join(best_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct vocab into a frozenset for the lrucache decorator\n",
    "vocabulary = frozenset(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10645.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'she is king to the per'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test example for unigram\n",
    "text = \"Seh is ging t te perk\"\n",
    "corrector_with_beam_search(text, vocabulary, ngram_counts, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10205.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'she is going to the park'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test example for bigram\n",
    "text = \"Seh is ging t te perk\"\n",
    "corrector_with_beam_search(text, vocabulary, ngram_counts, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2605.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'she is going to the park'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test example for trigram\n",
    "text = \"Seh is ging t te perk\"\n",
    "corrector_with_beam_search(text, vocabulary, ngram_counts, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11366.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'she is going tx ye peru'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test example for N-gram model\n",
    "text = \"Seh is ging t te perk\"\n",
    "corrector_with_beam_search(text, vocabulary, ngram_counts, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions to calculate WER and CER\n",
    "def calculate_wer(reference, corrected):\n",
    "    # Calculate Word Error Rate (WER)\n",
    "    reference_words = reference.split()\n",
    "    corrected_words = corrected.split()\n",
    "\n",
    "    S = Levenshtein(reference_words, corrected_words)\n",
    "    I = max(0, len(corrected_words) - len(reference_words))\n",
    "    D = max(0, len(reference_words) - len(corrected_words))\n",
    "\n",
    "    N = max(len(reference_words), len(corrected_words))\n",
    "\n",
    "    wer = (S + I + D) / N\n",
    "\n",
    "    return wer\n",
    "\n",
    "def calculate_cer(reference, corrected):\n",
    "    # Calculate Character Error Rate (CER)\n",
    "    S = Levenshtein(reference, corrected)\n",
    "    I = max(0, len(corrected) - len(reference))\n",
    "    D = max(0, len(reference) - len(corrected))\n",
    "\n",
    "    N = max(len(reference), len(corrected))\n",
    "\n",
    "    cer = (S + I + D) / N\n",
    "\n",
    "    return cer\n",
    "\n",
    "def compute_metrics_for_ngram_models(df, vocabulary, ngram_counts, n = 3):\n",
    "    WER = []\n",
    "    CER = []\n",
    "    \n",
    "    corrected_sentences = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    # Correct the sentences using the beam search corrector\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        misspelled_sentence = row['Misspelled Sentence']\n",
    "        reference = row['Original Sentence']\n",
    "        corrected_sentence = corrector_with_beam_search(misspelled_sentence, vocabulary, ngram_counts, n=n)\n",
    "        corrected_sentences.append(corrected_sentence)\n",
    "                \n",
    "        # Calculate WER and CER\n",
    "        wer = calculate_wer(reference, corrected_sentence)\n",
    "        cer = calculate_cer(reference, corrected_sentence)\n",
    "        WER.append(wer)\n",
    "        CER.append(cer)\n",
    "        \n",
    "        # Compute the accuracy\n",
    "        list_of_corrected_words = ast.literal_eval(row['Correct Words'])\n",
    "        for word in list_of_corrected_words:\n",
    "            if word in corrected_sentence:\n",
    "                correct_predictions += 1\n",
    "            total_predictions += 1\n",
    "                    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    if n == 2:\n",
    "        sentences = corrected_sentences\n",
    "        HC, perplexity = compute_perplexity_bigram_avg(sentences, ngram_counts, best_bigram_alpha)\n",
    "        print(f\"Perplexity: {perplexity}\")\n",
    "        print(f\"Cross-Entropy: {HC}\")\n",
    "    if n == 3:\n",
    "        sentences = corrected_sentences\n",
    "        HC, perplexity = compute_perplexity_interpolated_avg(sentences, ngram_counts, best_interpolated_alpha, best_interpolated_lambda)\n",
    "        print(f\"Perplexity: {perplexity}\")\n",
    "        print(f\"Cross-Entropy: {HC}\")\n",
    "        \n",
    "        \n",
    "    print('Average Word Error Rate (WER):', np.mean(WER))\n",
    "    print('Average Character Error Rate (CER):', np.mean(CER))\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    df[\"Corrected Sentence\"] = corrected_sentences\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolated model perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2221.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10512.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11748.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9776.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3701.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3968.12it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5722.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10866.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9198.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9198.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4048.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1158.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7869.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3953.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10645.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4739.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6052.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8683.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7307.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6909.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s] \n",
      "100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9619.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3010.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3030.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10512.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14074.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11214.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4505.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3097.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10645.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3744.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15363.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10894.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11096.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9446.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14716.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11096.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12483.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11214.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4877.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14074.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11881.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7307.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11397.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4485.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7463.17it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14074.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11366.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5047.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13189.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13025.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5210.32it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11214.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5152.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7244.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1879.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7869.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8473.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13934.56it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3701.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16131.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4634.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9709.04it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6335.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2481.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2739.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11214.72it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3368.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5096.36it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12710.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4809.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11244.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8612.53it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14768.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5315.97it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11096.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4236.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12228.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12300.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4777.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14563.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15141.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12018.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9177.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11881.88it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11781.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3890.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6990.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6754.11it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4116.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10727.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14979.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11881.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6452.78it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15887.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14217.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12710.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6278.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5777.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8630.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4634.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8756.38it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12483.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3355.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3788.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5745.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15141.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4609.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4181.76it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11748.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13025.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4951.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8867.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14074.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14027.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6213.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12945.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1889.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12945.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3634.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16384.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4999.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11096.04it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4788.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 938.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5184.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1772.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11881.88it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11781.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15141.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5577.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3460.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11125.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10894.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7570.95it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11366.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1183.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4364.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4975.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3890.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4505.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5053.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12228.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5614.86it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13315.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11781.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10837.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11781.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9341.43it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2746.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14074.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1721.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3206.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3412.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15887.52it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6668.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9446.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9489.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14716.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3334.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11881.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7516.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3679.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8338.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9986.44it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3956.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8701.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8322.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7244.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7002.18it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12018.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5077.85it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11096.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5584.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4401.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11522.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2308.37it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7096.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11096.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8943.08it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1501.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2947.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2470.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7810.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1949.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15887.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12483.05it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15827.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10754.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12228.29it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1173.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12446.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9489.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10645.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 769.74it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6335.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4691.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3622.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4013.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13025.79it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11125.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5645.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2709.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11214.72it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4860.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4733.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7681.88it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4899.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9822.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8128.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14027.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13315.25it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15141.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6132.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5236.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4604.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3204.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4391.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13400.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13934.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5652.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11650.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11459.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12945.38it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5753.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10305.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3104.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2277.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2605.16it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5053.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7516.67it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4382.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3077.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6721.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11096.04it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10979.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4629.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13934.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4136.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11275.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4809.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10754.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11522.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5706.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12018.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5412.01it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12228.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8338.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4946.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15141.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4899.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12157.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5315.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13315.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6492.73it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9425.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4837.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6364.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9915.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12228.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2226.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5152.71it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11650.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11748.75it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12300.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10305.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11008.67it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5475.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14716.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7695.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2159.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11214.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5343.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9709.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1406.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1992.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8338.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11781.75it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9892.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9098.27it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11397.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5322.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6278.90it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3692.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6335.81it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3236.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7002.18it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13189.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11881.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11275.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14217.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4629.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12157.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6615.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3775.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12018.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2644.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12865.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10866.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4236.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5029.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15141.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14563.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9341.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10538.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13025.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15420.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4718.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6990.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12157.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9642.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4922.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6061.13it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9709.04it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10979.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8867.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10645.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3216.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10512.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7345.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1883.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5165.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5236.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8756.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6932.73it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3460.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3194.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14716.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4387.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14563.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13189.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2739.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5645.09it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9986.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4718.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4877.10it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4609.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8388.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12228.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8405.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11366.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5229.81it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8701.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6213.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10538.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13315.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9619.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11397.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2755.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11748.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4271.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11748.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5915.80it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10894.30it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5343.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3847.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5777.28it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14074.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5825.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5489.93it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4036.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10512.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5398.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12483.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8594.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12945.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3226.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13025.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4696.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13315.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9822.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4443.12it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5949.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12865.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11522.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6168.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11366.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10645.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5152.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5343.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8144.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8388.61it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10538.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2168.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6452.78it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15363.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8701.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2839.75it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11214.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9000.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8128.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11522.81it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12483.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4744.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10754.63it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5178.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9078.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8208.03it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3204.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11459.85it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8542.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6594.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4744.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 886.56it/s]\n",
      "100%|██████████| 666/666 [00:34<00:00, 19.27it/s]\n",
      "Computing Perplexity: 100%|██████████| 666/666 [00:00<00:00, 2386.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 98373.00000000065\n",
      "Cross-Entropy: 16.585974779349506\n",
      "Average Word Error Rate (WER): 0.18588203716488597\n",
      "Average Character Error Rate (CER): 0.0815851399508757\n",
      "Accuracy: 0.360908041554444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "updated = compute_metrics_for_ngram_models(test_df.copy(), vocabulary, ngram_counts, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled Sentence: 1 nigel thrush page 48 i have four in my family dad mum and siter\n",
      "Misspleed Words: ['siter']\n",
      "Corrected: m1 nigel thrust page 48 in have four in my family dad sum and sister\n",
      "Target: 1 nigel thrush page 48 i have four in my family dad mum and sister\n",
      "-----------------------------\n",
      "Misspelled Sentence: my siter go to tonbury\n",
      "Misspleed Words: ['siter', 'go']\n",
      "Corrected: my sister go to tonbury\n",
      "Target: my sister goes to tonbury\n",
      "-----------------------------\n",
      "Misspelled Sentence: my mum goes out sometimes\n",
      "Misspleed Words: ['sometimes']\n",
      "Corrected: my um goes out sometimes\n",
      "Target: my mum goes out sometimes\n",
      "-----------------------------\n",
      "Misspelled Sentence: i go to bridgebrook i go out sometimes on tuesday night i go to youth clob\n",
      "Misspleed Words: ['sometimes', 'clob']\n",
      "Corrected: it go to bridgebrook xi go out sometimes on tuesday night in go to youth club\n",
      "Target: i go to bridgebrook i go out sometimes on tuesday night i go to youth club\n",
      "-----------------------------\n",
      "Misspelled Sentence: on thursday nights i go bellringing on saturdays i go down to the farm\n",
      "Misspleed Words: ['bellringing']\n",
      "Corrected: on thursday nights it go bellringing on saturday it go down to the farm\n",
      "Target: on thursday nights i go bellringing on saturdays i go down to the farm\n",
      "-----------------------------\n",
      "Misspelled Sentence: i go to bed at 10 o clock i wakh tv at 5 o clock i live in a house\n",
      "Misspleed Words: ['wakh']\n",
      "Corrected: it go to bed at 10 to clock is wake tv at 5p to clock in live in an house\n",
      "Target: i go to bed at 10 o clock i watch tv at 5 o clock i live in a house\n",
      "-----------------------------\n",
      "Misspelled Sentence: the house is white it has stone up the frount it is the first from bridgebrook and the sexeon from smallerden\n",
      "Misspleed Words: ['frount', 'sexeon']\n",
      "Corrected: the house is white it has stone up the front it is the first from bridgebrook and the season from smallerden\n",
      "Target: the house is white it has stone up the front it is the first from bridgebrook and the second from smallerden\n",
      "-----------------------------\n",
      "Misspelled Sentence: on monday i sometimes go down the farm in the night i wach tv there is bbc and itv\n",
      "Misspleed Words: ['wach']\n",
      "Corrected: on monday it sometimes go down the farm in the night in each tv there is bbc and it\n",
      "Target: on monday i sometimes go down the farm in the night i watch tv there is bbc and itv\n",
      "-----------------------------\n",
      "Misspelled Sentence: we have got anglia like to wach cowboys\n",
      "Misspleed Words: ['wach', 'cowboys']\n",
      "Corrected: we have got anglican like to each cowboy\n",
      "Target: we have got anglia like to watch cowboys\n",
      "-----------------------------\n",
      "Misspelled Sentence: on tuesday i get off the bus and sometimes in the night i go to the youth colbe\n",
      "Misspleed Words: ['sometimes', 'colbe']\n",
      "Corrected: on tuesday it get off the bus and sometimes in the night it go to the youth cole\n",
      "Target: on tuesday i get off the bus and sometimes in the night i go to the youth club\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# print examples of fixes\n",
    "for i in range(10):\n",
    "    print(f\"Misspelled Sentence: {test_df['Misspelled Sentence'][i]}\")\n",
    "    print(f\"Misspleed Words: {test_df['Misspelled Words'][i]}\")\n",
    "    print(f\"Corrected: {updated['Corrected Sentence'][i]}\")\n",
    "    print(f\"Target: {test_df['Original Sentence'][i]}\")\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram model perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1941.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8050.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 791.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2605.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13025.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4100.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11244.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4975.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13189.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15196.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6326.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10205.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8338.58it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11335.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6668.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5882.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10645.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 927.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4650.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10205.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8848.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6765.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8405.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2931.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10538.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8473.34it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10407.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8422.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4899.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13934.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11096.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9642.08it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14074.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9258.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9892.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15141.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14716.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10618.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12865.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9157.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6288.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13315.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15087.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14979.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16194.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12018.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11881.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9709.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11881.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4236.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6668.21it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1234.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3634.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10754.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4198.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10754.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3050.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3688.92it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10951.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6132.02it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2123.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9597.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9986.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8867.45it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10106.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4899.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2785.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11748.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4568.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4782.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8630.26it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7810.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4405.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7410.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10782.27it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8612.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5017.11it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6297.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7096.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5184.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9709.04it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4253.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8542.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4293.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10894.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4529.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3163.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2890.63it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8473.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5777.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4588.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4899.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4860.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13400.33it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4760.84it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12483.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5071.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6052.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3437.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4604.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9000.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5518.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5210.32it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5983.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4116.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10305.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8128.50it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15650.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14979.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1904.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8867.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6574.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12865.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6177.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7752.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6105.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7810.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13315.25it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4766.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6533.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16448.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6543.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13189.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15827.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11335.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9157.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3688.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2012.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4466.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1449.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5127.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4002.20it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9078.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7397.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4116.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11781.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3483.64it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4696.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8701.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4999.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10407.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11125.47it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3715.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8405.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3844.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4718.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4424.37it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6898.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6853.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15420.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3715.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3816.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5957.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13025.79it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8542.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4946.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6297.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4198.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6462.72it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5622.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5236.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6423.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2716.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4253.86it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5377.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11125.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4809.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11366.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11125.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4429.04it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4169.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9776.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3731.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4505.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10645.44it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1952.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9238.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6069.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5461.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15141.89it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9986.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11335.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9425.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11397.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5809.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6842.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9446.63it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3358.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11244.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3721.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3785.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8192.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6853.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3731.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9177.91it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13189.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4975.45it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8422.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9709.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4588.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13842.59it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8065.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3246.37it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14563.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2841.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13025.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14563.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8192.00it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9986.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2238.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15363.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12945.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10305.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11522.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9892.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7884.03it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10305.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 993.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13617.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 760.53it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1222.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6502.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10512.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12483.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7397.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1418.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12087.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11008.67it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15363.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10951.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14027.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3788.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4975.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15196.75it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14768.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11618.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10645.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5236.33it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4739.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10866.07it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12300.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2505.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2957.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3575.71it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9822.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14217.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3851.52it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3039.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4568.96it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11335.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10866.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3659.95it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4999.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4877.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9098.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10979.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10754.63it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10837.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2898.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5949.37it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6105.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1531.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5121.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11748.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4568.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6584.46it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4219.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9362.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10305.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7626.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13189.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10951.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13934.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5949.37it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5370.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10433.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4804.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13934.56it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9986.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11881.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4670.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5849.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5262.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9000.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9822.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8701.88it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14463.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7710.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4524.60it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10512.04it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9892.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10782.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11214.72it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6096.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9000.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1300.56it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13888.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5108.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4284.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4782.56it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10618.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4064.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3983.19it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6223.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5675.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3919.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9341.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10866.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10407.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9709.04it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6141.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8924.05it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11781.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8701.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8559.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1110.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6017.65it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6710.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3287.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11366.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3819.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4215.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3498.17it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4258.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3718.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2801.81it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1953.56it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3600.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8943.08it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7194.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10645.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14315.03it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8559.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14074.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4899.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10979.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9776.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4609.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2416.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2824.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13025.79it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5683.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4766.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6250.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10894.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5555.37it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7358.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8924.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3437.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10205.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2004.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6026.30it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14513.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10727.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7854.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4809.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6492.73it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4002.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4951.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5907.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2475.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6574.14it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4382.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12483.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10305.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5991.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4202.71it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10866.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9619.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4084.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9868.95it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8473.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14926.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4877.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11214.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12826.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11335.96it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2236.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4655.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3650.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6853.44it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7516.67it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12710.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11748.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11096.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4485.89it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4116.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7943.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5433.04it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5777.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14716.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10754.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12372.58it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5405.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13315.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3134.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11008.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12192.74it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9341.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9258.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2090.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3923.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12520.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13706.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11748.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6574.14it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10866.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10205.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12865.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2597.09it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4563.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10754.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12018.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14122.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11096.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6413.31it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12945.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11244.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1933.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3983.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12228.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6316.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3802.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2657.99it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11491.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14665.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3495.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6754.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 148.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3344.74it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13025.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11781.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9915.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6403.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5714.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4718.00it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3184.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13934.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13148.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5127.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13189.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9686.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4116.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7084.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13486.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8943.08it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12336.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9157.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12671.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12633.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5526.09it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3771.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4691.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9686.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11915.64it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3204.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3701.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3048.19it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14716.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9157.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10866.07it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12787.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11781.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10106.76it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8924.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6721.64it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8848.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10205.12it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1608.25it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10305.42it/s]]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13530.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12052.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 4882.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12985.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 9098.27it/s]s]\n",
      "100%|██████████| 666/666 [00:36<00:00, 18.05it/s]\n",
      "Computing Perplexity: 100%|██████████| 666/666 [00:00<00:00, 4257.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 98373.00000000065\n",
      "Cross-Entropy: 16.585974779349506\n",
      "Average Word Error Rate (WER): 0.1869153014145821\n",
      "Average Character Error Rate (CER): 0.08206445300109326\n",
      "Accuracy: 0.3528280107733744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "updated = compute_metrics_for_ngram_models(test_df.copy(), vocabulary, ngram_counts, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misspelled Sentence: 1 nigel thrush page 48 i have four in my family dad mum and siter\n",
      "Misspleed Words: ['siter']\n",
      "Corrected: m1 nigel thrust page 48 in have four in my family dad sum and sister\n",
      "Target: 1 nigel thrush page 48 i have four in my family dad mum and sister\n",
      "-----------------------------\n",
      "Misspelled Sentence: my siter go to tonbury\n",
      "Misspleed Words: ['siter', 'go']\n",
      "Corrected: my sister go to tonbury\n",
      "Target: my sister goes to tonbury\n",
      "-----------------------------\n",
      "Misspelled Sentence: my mum goes out sometimes\n",
      "Misspleed Words: ['sometimes']\n",
      "Corrected: my um goes out sometimes\n",
      "Target: my mum goes out sometimes\n",
      "-----------------------------\n",
      "Misspelled Sentence: i go to bridgebrook i go out sometimes on tuesday night i go to youth clob\n",
      "Misspleed Words: ['sometimes', 'clob']\n",
      "Corrected: it go to bridgebrook xi go out sometimes on tuesday night in go to youth club\n",
      "Target: i go to bridgebrook i go out sometimes on tuesday night i go to youth club\n",
      "-----------------------------\n",
      "Misspelled Sentence: on thursday nights i go bellringing on saturdays i go down to the farm\n",
      "Misspleed Words: ['bellringing']\n",
      "Corrected: on thursday nights it go bellringing on saturday it go down to the farm\n",
      "Target: on thursday nights i go bellringing on saturdays i go down to the farm\n",
      "-----------------------------\n",
      "Misspelled Sentence: i go to bed at 10 o clock i wakh tv at 5 o clock i live in a house\n",
      "Misspleed Words: ['wakh']\n",
      "Corrected: it go to bed at 10 or clock is wake tv at 5p to clock in live in an house\n",
      "Target: i go to bed at 10 o clock i watch tv at 5 o clock i live in a house\n",
      "-----------------------------\n",
      "Misspelled Sentence: the house is white it has stone up the frount it is the first from bridgebrook and the sexeon from smallerden\n",
      "Misspleed Words: ['frount', 'sexeon']\n",
      "Corrected: the house is white it has stone up the front it is the first from bridgebrook and the season from smallerden\n",
      "Target: the house is white it has stone up the front it is the first from bridgebrook and the second from smallerden\n",
      "-----------------------------\n",
      "Misspelled Sentence: on monday i sometimes go down the farm in the night i wach tv there is bbc and itv\n",
      "Misspleed Words: ['wach']\n",
      "Corrected: on monday it sometimes go down the farm in the night in each tv there is bbc and it\n",
      "Target: on monday i sometimes go down the farm in the night i watch tv there is bbc and itv\n",
      "-----------------------------\n",
      "Misspelled Sentence: we have got anglia like to wach cowboys\n",
      "Misspleed Words: ['wach', 'cowboys']\n",
      "Corrected: we have got anglican like to each cowboy\n",
      "Target: we have got anglia like to watch cowboys\n",
      "-----------------------------\n",
      "Misspelled Sentence: on tuesday i get off the bus and sometimes in the night i go to the youth colbe\n",
      "Misspleed Words: ['sometimes', 'colbe']\n",
      "Corrected: on tuesday it get off the bus and sometimes in the night it go to the youth cole\n",
      "Target: on tuesday i get off the bus and sometimes in the night i go to the youth club\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# print examples of fixes\n",
    "for i in range(10):\n",
    "    print(f\"Misspelled Sentence: {test_df['Misspelled Sentence'][i]}\")\n",
    "    print(f\"Misspleed Words: {test_df['Misspelled Words'][i]}\")\n",
    "    print(f\"Corrected: {updated['Corrected Sentence'][i]}\")\n",
    "    print(f\"Target: {test_df['Original Sentence'][i]}\")\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution №2 N-gram model based on the Google Books n-gram API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "class ContextualSpellingCorrector:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocabulary = set(vocabulary)\n",
    "\n",
    "    def run_query(self, query, start_year=2010, end_year=2019, corpus=26, smoothing=3):\n",
    "        \"\"\"Fetches frequency data from the Google Books Ngram API.\"\"\"\n",
    "        query = urllib.parse.quote(query)\n",
    "        url = f'https://books.google.com/ngrams/json?content={query}&year_start={start_year}&year_end={end_year}&corpus={corpus}&smoothing={smoothing}'\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        try:\n",
    "            output = response.json()\n",
    "        except:\n",
    "            return {}\n",
    "\n",
    "        if not output:\n",
    "            return {}\n",
    "\n",
    "        return {entry['ngram']: sum(entry['timeseries']) / len(entry['timeseries']) for entry in output}\n",
    "\n",
    "    def average_frequency(self, phrase):\n",
    "        \"\"\"Gets the average frequency of a word or n-gram phrase from Google Ngrams.\"\"\"\n",
    "        data = self.run_query(phrase)\n",
    "        return sum(data.values()) / len(data) if data else 0\n",
    "\n",
    "    def words(self, text):\n",
    "        \"\"\"Tokenizes and lowercases the input text.\"\"\"\n",
    "        return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "    def correction_with_context(self, word, context_window):\n",
    "        \"\"\"Finds the best spelling correction by considering context-based n-gram probabilities.\"\"\"\n",
    "        candidates = self.candidates(word)\n",
    "        \n",
    "        # Generate n-grams with the surrounding context\n",
    "        context_phrases = {candidate: self.form_context_phrases(candidate, context_window) for candidate in candidates}\n",
    "\n",
    "        # Get frequencies for each candidate within its context\n",
    "        context_frequencies = {\n",
    "            candidate: sum(self.average_frequency(phrase) for phrase in phrases)\n",
    "            for candidate, phrases in context_phrases.items()\n",
    "        }\n",
    "\n",
    "        return max(context_frequencies, key=context_frequencies.get)  # Return the best correction\n",
    "\n",
    "    def form_context_phrases(self, candidate, context_window):\n",
    "        \"\"\"Forms bigram and trigram phrases including the candidate.\"\"\"\n",
    "        left_context, right_context = context_window\n",
    "        phrases = []\n",
    "\n",
    "        if left_context:\n",
    "            phrases.append(f\"{left_context} {candidate}\")\n",
    "        if right_context:\n",
    "            phrases.append(f\"{candidate} {right_context}\")\n",
    "        if left_context and right_context:\n",
    "            phrases.append(f\"{left_context} {candidate} {right_context}\")\n",
    "\n",
    "        return phrases\n",
    "\n",
    "    def candidates(self, word):\n",
    "        \"\"\"Generates possible spelling corrections based on known words.\"\"\"\n",
    "        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word])\n",
    "\n",
    "    def known(self, words):\n",
    "        \"\"\"Filters words that exist in the vocabulary.\"\"\"\n",
    "        return set(w for w in words if w in self.vocabulary)\n",
    "\n",
    "    def edits1(self, word):\n",
    "        \"\"\"Generates possible single-edit variations of a word.\"\"\"\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes = [L + R[1:] for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "        inserts = [L + c + R for L, R in splits for c in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "    def edits2(self, word):\n",
    "        \"\"\"Generates possible double-edit variations of a word.\"\"\"\n",
    "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))\n",
    "\n",
    "# Load corpus and build vocabulary\n",
    "with open(\"data/train/large_corpus.txt\") as f:\n",
    "    train_corpus = f.read()\n",
    "\n",
    "vocabulary = set(re.findall(r'\\w+', train_corpus.lower()))\n",
    "vocabulary.update([\"<START>\", \"<END>\"])  # Add special tokens\n",
    "\n",
    "# Initialize corrector with updated vocabulary\n",
    "corrector = ContextualSpellingCorrector(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize corrector\n",
    "corrector = ContextualSpellingCorrector(vocabulary)\n",
    "\n",
    "# Example usage with context-aware spelling correction\n",
    "sentence = [\"this\", \"is\", \"a\", \"speling\", \"error\"]\n",
    "corrected_list = []\n",
    "\n",
    "for i, word in enumerate(sentence):\n",
    "    left_context = sentence[i - 1] if i > 0 else \"<START>\"\n",
    "    right_context = sentence[i + 1] if i < len(sentence) - 1 else \"<END>\"\n",
    "    \n",
    "    corrected_word = corrector.correction_with_context(word, (left_context, right_context))\n",
    "    corrected_list.append(corrected_word)\n",
    "\n",
    "corrected_sentence = \" \".join(corrected_list)\n",
    "print(f\"Corrected sentence: {corrected_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each sentence\n",
    "corrected_sentences = []\n",
    "corrected_words_list = []\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    misspelled_sentence = word_tokenize(row[\"Misspelled Sentence\"])  # Tokenize sentence\n",
    "    corrected_words = []  # Store corrected words\n",
    "    \n",
    "    corrected_sentence = []\n",
    "    for i, word in enumerate(misspelled_sentence):\n",
    "        left_context = misspelled_sentence[i - 1] if i > 0 else \"<START>\"\n",
    "        right_context = misspelled_sentence[i + 1] if i < len(misspelled_sentence) - 1 else \"<END>\"\n",
    "\n",
    "        corrected_word = corrector.correction_with_context(word, (left_context, right_context))\n",
    "        corrected_sentence.append(corrected_word)\n",
    "        \n",
    "        # If the word was corrected, add it to the corrected words list\n",
    "        if corrected_word != word:\n",
    "            corrected_words.append((word, corrected_word))\n",
    "\n",
    "    # Store results\n",
    "    corrected_sentences.append(\" \".join(corrected_sentence))\n",
    "    corrected_words_list.append(corrected_words)\n",
    "    break\n",
    "\n",
    "# Add results to DataFrame\n",
    "print(corrected_sentences)\n",
    "print(corrected_words_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
